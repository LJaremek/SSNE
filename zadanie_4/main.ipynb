{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0wPwnCj42U0L"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from random import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.set_device(0)\n",
        "device = torch.device(\"cuda\")\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(1337)\n",
        "    torch.cuda.manual_seed_all(1337)\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "np.random.seed(1337)\n",
        "\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EIs7pLF5Evaj"
      },
      "outputs": [],
      "source": [
        "with open(\"train.pkl\", \"rb\") as f:\n",
        "    data_train = pickle.load(f)\n",
        "\n",
        "with open(\"test_no_target.pkl\", \"rb\") as f:\n",
        "    data_test = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffle(data_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6nO8QTzcE04a"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "\n",
        "for data, label in data_train:\n",
        "    X_train.append(torch.Tensor(data))\n",
        "    y_train.append(torch.Tensor([label]))\n",
        "\n",
        "for data in data_test:\n",
        "    X_test.append(torch.Tensor(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7Yt5cmilHkej"
      },
      "outputs": [],
      "source": [
        "train_max_len = max([len(sequence) for sequence in X_train])\n",
        "test_max_len = max([len(sequence) for sequence in X_test])\n",
        "max_len = max([train_max_len, test_max_len])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JJS9xfFgHktZ"
      },
      "outputs": [],
      "source": [
        "def pad_collate(batch, pad_value=0):\n",
        "    \"\"\"\n",
        "    batch: list[tuple[torch.Tensor]]\n",
        "    \"\"\"\n",
        "    xx, yy = [list(element) for element in zip(*batch)]\n",
        "    x_lens = [len(x) for x in xx]\n",
        "    y_lens = [len(y) for y in yy]\n",
        "\n",
        "    xx[0] = nn.ConstantPad1d((0, max_len - xx[0].shape[0]), 0)(xx[0])\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy_pad, x_lens, y_lens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_collate_test(batch, pad_value=0):\n",
        "    \"\"\"\n",
        "    batch: list[tuple[torch.Tensor]]\n",
        "    \"\"\"\n",
        "    xx = list(batch)\n",
        "    x_len = xx[0].shape[0]\n",
        "\n",
        "    xx[0] = nn.ConstantPad1d((0, max_len - x_len), 0)(xx[0])\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, x_len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nGx-DZK-Jbz9"
      },
      "outputs": [],
      "source": [
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4PJPiAQvIxjD"
      },
      "outputs": [],
      "source": [
        "train_indices = int(len(data_train) * 0.7)\n",
        "\n",
        "train_set = VariableLenDataset(X_train[:train_indices], y_train[:train_indices])\n",
        "valid_set = VariableLenDataset(X_train[train_indices:], y_train[train_indices:])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=pad_collate)\n",
        "valid_loader = DataLoader(valid_set, batch_size=16, shuffle=False, drop_last=False, collate_fn=pad_collate)\n",
        "test_loader = DataLoader(X_test, batch_size=16, shuffle=False, drop_last=False, collate_fn=pad_collate_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(129, 56)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_QZmUOpQJ7-J"
      },
      "outputs": [],
      "source": [
        "iter_ = iter(train_loader)\n",
        "a = next(iter_)\n",
        "b = next(iter_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8966"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1riX3x7KC2q",
        "outputId": "7671e621-9c87-4377-c9e8-d2cef987d63d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8966])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0][0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZaxZ8W0-MWpu"
      },
      "outputs": [],
      "source": [
        "class BestNetEver2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, max_len, num_layers_LSTM, out_size, dropout):\n",
        "        super().__init__()\n",
        "        self.num_layers_LSTM = num_layers_LSTM\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers_LSTM, dropout=dropout)                  \n",
        "        self.fc_1 = nn.Linear(in_features=max_len * hidden_size, out_features=400)\n",
        "        self.fc_2 = nn.Linear(in_features=400, out_features=out_size)\n",
        "        self.act = nn.LeakyReLU()\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden_state = torch.zeros(self.num_layers_LSTM, batch_size, self.hidden_size)\n",
        "        cell_state = torch.zeros(self.num_layers_LSTM, batch_size, self.hidden_size)\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        all_outputs = torch.transpose(all_outputs, 0, 1)\n",
        "        out = torch.flatten(all_outputs, 1)\n",
        "        x = self.act(self.fc_1(out))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x, hidden\n",
        "\n",
        "\n",
        "model = BestNetEver2(input_size=1, hidden_size=17, max_len=max_len, num_layers_LSTM=2, out_size=5, dropout=0.6).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = pd.Series([int(y) for y in y_train]).sort_values()\n",
        "class_weights = classes.value_counts().sort_index()/classes.shape[0]\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))  # unballanced set\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0074012868626172\n",
            "0.6129858700572982\n",
            "0.5798968233803447\n",
            "0.563606707393661\n",
            "0.5558252698460291\n",
            "0.5141063116548598\n",
            "0.5083884172892386\n",
            "0.493249299798825\n",
            "0.4820827638456064\n",
            "0.467766653544219\n",
            "0.44127727998781574\n",
            "0.43961895944536195\n",
            "0.4347910625759021\n",
            "0.43638852273308953\n",
            "0.43161939096081164\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(15):\n",
        "    epoch_lossess = []\n",
        "    for x, targets, _, _ in train_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.type(torch.LongTensor)\n",
        "        targets = targets.to(device)\n",
        "        hidden_state, cell_state = model.init_hidden(x.size(0))\n",
        "        hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n",
        "        preds, _ = model(x, (hidden_state, cell_state))\n",
        "        preds = preds.squeeze(1)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = loss_fun(preds, targets.squeeze(1))\n",
        "        loss.backward()\n",
        "        \n",
        "        epoch_lossess.append(loss.item())\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_mean = np.array(epoch_lossess).mean()\n",
        "    torch.save(model.state_dict(), './model.pt')\n",
        "    print(loss_mean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Valid accuracy: 0.52'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct, all = 0, 0\n",
        "    for X, labels, _, _ in valid_loader:\n",
        "        X = X.to(device).unsqueeze(2)\n",
        "\n",
        "        hidden_state, state = model.init_hidden(X.size(0))\n",
        "        hidden_state, state = hidden_state.to(device), state.to(device)\n",
        "\n",
        "        preds, _ = model(X, (hidden_state,state))\n",
        "        preds = torch.argmax(preds, 1).cpu()\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        all += X.size(0)*16\n",
        "\n",
        "f'Valid accuracy: {round(correct/all, 2)}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    results = list()\n",
        "    for X, _ in test_loader:\n",
        "        X = X.to(device).unsqueeze(2)\n",
        "\n",
        "        hidden_state, state = model.init_hidden(X.size(0))\n",
        "        hidden_state, state = hidden_state.to(device), state.to(device)\n",
        "\n",
        "        preds, _ = model(X, (hidden_state,state))\n",
        "        preds = torch.argmax(preds, 1).cpu()\n",
        "\n",
        "        results += [int(i) for i in preds]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('ssne')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "fefba7ab84d2de9e566d8fee028ec3dc1e3f21c7f74d680889548c1a33856853"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
